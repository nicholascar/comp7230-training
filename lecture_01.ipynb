{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Guest Lecture COMP7230\n",
    "# Using Python packages for Linked Data & spatial data\n",
    "#### by Dr Nicholas Car\n",
    "\n",
    "This Notebook is the resource used to deliver a guest lecture for the [Australian National University](https://www.anu.edu.au)'s course [COMP7230](https://programsandcourses.anu.edu.au/2020/course/COMP7230): *Introduction to Programming for Data Scientists*\n",
    "\n",
    "Click here to run this lecture in your web browser:\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/nicholascar/comp7230-training/HEAD?filepath=lecture.ipynb)\n",
    "\n",
    "## About the lecturer\n",
    "**Nicholas Car**:\n",
    "* PhD in informatics for irrigation\n",
    "* A former CSIRO informatics researcher\n",
    "    * worked on integrating environmental data across government / industry\n",
    "    * developed data standards\n",
    "* Has worked in operation IT in government\n",
    "* Now in a private IT consulting company, [SURROUND Australia Pty Ltd](https://surroundaustralia.com) supplying Data Science solutions\n",
    "\n",
    "Relevant current work:\n",
    "\n",
    "* building data processing systems for government & industry\n",
    "* mainly using Python\n",
    "    * due to its large number of web and data science packages\n",
    "* maintains the [RDFlib](https://rdflib.net) Python toolkit\n",
    "    * for processing [RDF](https://en.wikipedia.org/wiki/Resource_Description_Framework)\n",
    "* co-chairs the [Australian Government Linked Data Working Group](https://www.linked.data.gov.au) with Armin Haller\n",
    "    * plans for multi-agency data integration\n",
    "* still developing data standards\n",
    "    * in particular GeoSPARQL 1.1 (https://opengeospatial.github.io/ogc-geosparql/geosparql11/spec.html) \n",
    "        * for graph representations of spatial information\n",
    "\n",
    "\n",
    "## 0. Lecture Outline\n",
    "1. Notes about this training material\n",
    "2. Accessing RDF data\n",
    "3. Parsing RDF data\n",
    "4. Data 'mash up'\n",
    "5. Data Conversions & Display\n",
    "\n",
    "\n",
    "## 1. Notes about this training material\n",
    "\n",
    "#### This tool\n",
    "* This is a Jupyter Notebook - interactive Python scripting\n",
    "* You will cover Jupyter Notebooks more, later in this course\n",
    "* Access this material online at:\n",
    "    * GitHub: <https://github.com/nicholascar/comp7230-training>\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/nicholascar/comp7230-training/?filepath=lecture.ipynb)\n",
    "\n",
    "#### Background data concepts - RDF\n",
    "\n",
    "_Nick will talk RDF using these web pages:_\n",
    "    * [Semantic Web](https://www.w3.org/standards/semanticweb/) - the concept\n",
    "    * [RDF](https://en.wikipedia.org/wiki/Resource_Description_Framework) - the data model\n",
    "        * refer to the RDF image below\n",
    "    * [RDFlib](https://rdflib.net) - the (Python) toolkit\n",
    "    * [RDFlib training Notebooks are available](https://github.com/surroundaustralia/rdflib-training)\n",
    "\n",
    "The LocI project:\n",
    "* The Location Index project: <http://loci.cat>\n",
    "\n",
    "RDF image, from [the RDF Primer](https://www.w3.org/TR/rdf11-primer/), for discussion:\n",
    "\n",
    "![](img/example-graph-iris.png)\n",
    "\n",
    "Note that:\n",
    "* _everything_ is \"strongly\" identified\n",
    "    * including all relationships\n",
    "    * unlike lots of related data\n",
    "* many of the identifiers resolve\n",
    "    * to more info (on the web)\n",
    "\n",
    "## 2. Accessing RDF data\n",
    "\n",
    "* Here we use an online structured dataset, the Geocoded National Address File for Australia\n",
    "    * Dataset Persistent Identifier: <https://linked.data.gov.au/dataset/gnaf>\n",
    "    * The above link redirects to the API at <https://gnafld.net>\n",
    "* GNAF-LD Data is presented according to *Linked Data* principles\n",
    "    * online\n",
    "    * in HTML & machine-readable form, RDF\n",
    "    * RDF is a Knowledge Graph: a graph containing data + model\n",
    "    * each resource is available via a URI\n",
    "        * e.g. <https://linked.data.gov.au/dataset/gnaf/address/GAACT714845933>\n",
    "\n",
    "![GAACT714845933](img/GAACT714845933.png)\n",
    "\n",
    "\n",
    "2.1. Get the Address GAACT714845933 using the *requests* package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import requests  # NOTE: you must have installed requests first, it's not a standard package\n",
    "r = requests.get(\n",
    "    \"https://linked.data.gov.au/dataset/gnaf/address/GAACT714845933\"\n",
    ")\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Get machine-readable data, RDF triples\n",
    "Use HTTP Content Negotiation\n",
    "Same URI, different *format* of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "r = requests.get(\n",
    "    \"https://linked.data.gov.au/dataset/gnaf/address/GAACT714845933\",\n",
    "    headers={\"Accept\": \"application/n-triples\"}\n",
    ")\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Get machine-readable data, Turtle\n",
    "Easier to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "r = requests.get(\n",
    "    \"https://linked.data.gov.au/dataset/gnaf/address/GAACT714845933\",\n",
    "    headers={\"Accept\": \"text/turtle\"}\n",
    ")\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parsing RDF data\n",
    "\n",
    "Import the RDFlib library for manipulating RDF data\n",
    "Add some namespaces to shorten URIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import rdflib\n",
    "from rdflib.namespace import RDF, RDFS\n",
    "GNAF = rdflib.Namespace(\"http://linked.data.gov.au/def/gnaf#\")\n",
    "ADDR = rdflib.Namespace(\"http://linked.data.gov.au/dataset/gnaf/address/\")\n",
    "GEO = rdflib.Namespace(\"http://www.opengis.net/ont/geosparql#\")\n",
    "print(GEO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create a graph and add the namespaces to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "g = rdflib.Graph()\n",
    "g.bind(\"gnaf\", GNAF)\n",
    "g.bind(\"addr\", ADDR)\n",
    "g.bind(\"geo\", GEO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse in the machine-readable data from the GNAF-LD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "r = requests.get(\n",
    "    \"https://linked.data.gov.au/dataset/gnaf/address/GAACT714845933\",\n",
    "    headers={\"Accept\": \"text/turtle\"}\n",
    ")\n",
    "g.parse(data=r.text, format=\"text/turtle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print graph length (no. of triples) to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print graph content, in Turtle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(g.serialize(format=\"text/turtle\").decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Getting multi-address data:\n",
    "3.1.1. Retrieve an index of 10 addresses, in RDF\n",
    "3.1.2. For each address in the index, get each Address' data\n",
    "* use paging URI: <https://linked.data.gov.au/dataset/gnaf/address/?page=1>\n",
    "3.1.3. Get only the street address and map coordinates\n",
    "\n",
    "#### 3.1.1. Retrieve index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# clear the graph\n",
    "g = rdflib.Graph()\n",
    "\n",
    "r = requests.get(\n",
    "    \"https://linked.data.gov.au/dataset/gnaf/address/?page=1\",\n",
    "    headers={\"Accept\": \"text/turtle\"}\n",
    ")\n",
    "g.parse(data=r.text, format=\"text/turtle\")\n",
    "print(len(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3.1.2. Parse in each address' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for s, p, o in g.triples((None, RDF.type, GNAF.Address)):\n",
    "    print(s.split(\"/\")[-1])\n",
    "    r = requests.get(\n",
    "        str(s),\n",
    "        headers={\"Accept\": \"text/turtle\"}\n",
    "    )\n",
    "    g.parse(data=r.text, format=\"turtle\")\n",
    "    print(len(g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph model used by the GNAF-LD is based on [GeoSPARQL 1.1](https://opengeospatial.github.io/ogc-geosparql/geosparql11/spec.html) and looks like this:\n",
    "\n",
    "![](img/geosparql-model.png)\n",
    "\n",
    "#### 3.1.3. Extract (& print) street address text & coordinates\n",
    "(CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "addresses_tsv = \"GNAF ID\\tAddress\\tCoordinates\\n\"\n",
    "for s, p, o in g.triples((None, RDF.type, GNAF.Address)):\n",
    "    for s2, p2, o2 in g.triples((s, RDFS.comment, None)):\n",
    "        txt = str(o2)\n",
    "    for s2, p2, o2 in g.triples((s, GEO.hasGeometry, None)):\n",
    "        for s3, p3, o3 in g.triples((o2, GEO.asWKT, None)):\n",
    "            coords = str(o3).replace(\"<http://www.opengis.net/def/crs/EPSG/0/4283> \", \"\")\n",
    "\n",
    "    addresses_tsv += \"{}\\t{}\\t{}\\n\".format(str(s).split(\"/\")[-1], txt, coords)\n",
    "\n",
    "print(addresses_tsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4. Convert CSV data to PANDAS DataFrame\n",
    "(CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from io import StringIO\n",
    "s = StringIO(addresses_tsv)\n",
    "df1 = pandas.read_csv(s, sep=\"\\t\")\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.5. SPARQL querying RDF data\n",
    "A graph query, similar to a database SQL query, can traverse the graph and retrieve the same details as the multiple\n",
    "loops and Python code above in 3.1.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "SELECT ?id ?addr ?coords\n",
    "WHERE {\n",
    "    ?uri a gnaf:Address ;\n",
    "         rdfs:comment ?addr .\n",
    "\n",
    "    ?uri geo:hasGeometry/geo:asWKT ?coords_dirty .\n",
    "\n",
    "    BIND (STRAFTER(STR(?uri), \"address/\") AS ?id)\n",
    "    BIND (STRAFTER(STR(?coords_dirty), \"4283> \") AS ?coords)\n",
    "}\n",
    "ORDER BY ?id\n",
    "\"\"\"\n",
    "for r in g.query(q):\n",
    "    print(\"{}, {}, {}\".format(r[\"id\"], r[\"addr\"], r[\"coords\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data 'mash up'\n",
    "Add some fake data to the GNAF data - people count per address.\n",
    "\n",
    "The GeoSPARQL model extension used is:\n",
    "\n",
    "![](img/geosparql-model-extension.png)\n",
    "\n",
    "Note that for real Semantic Web work, the `xxx:` properties and classes would be \"properly defined\", removing any ambiguity of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           GNAF ID   Persons\n",
      "0   GAACT714845944         3\n",
      "1   GAACT714845934         5\n",
      "2   GAACT714845943        10\n",
      "3   GAACT714845949         1\n",
      "4   GAACT714845955         2\n",
      "5   GAACT714845935         1\n",
      "6   GAACT714845947         4\n",
      "7   GAACT714845950         3\n",
      "8   GAACT714845933         4\n",
      "9   GAACT714845953         2\n",
      "10  GAACT714845945         3\n",
      "11  GAACT714845946         3\n",
      "12  GAACT714845939         4\n",
      "13  GAACT714845941         2\n",
      "14  GAACT714845942         1\n",
      "15  GAACT714845954         0\n",
      "16  GAACT714845952         5\n",
      "17  GAACT714845938         3\n",
      "18  GAACT714845936         4\n",
      "19  GAACT714845951         3\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "df2 = pandas.read_csv('fake_data.csv')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df3 = pandas.merge(df1, df2)\n",
    "print(df3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 5. Spatial Data Conversions & Display\n",
    "\n",
    "Often you will want to display or export data.\n",
    "\n",
    "#### 5.1 Display directly in Jupyter\n",
    "Using standard Python plotting (matplotlib).\n",
    "\n",
    "First, extract addresses, longitudes & latitudes into a dataframe using a SPARQL query to build a CSV string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "addresses_csv = \"Address,Longitude,Latitude\\n\"\n",
    "\n",
    "q = \"\"\"\n",
    "    SELECT ?addr ?coords\n",
    "    WHERE {\n",
    "        ?uri a gnaf:Address ;\n",
    "             rdfs:comment ?addr .\n",
    "\n",
    "        ?uri geo:hasGeometry/geo:asWKT ?coords .\n",
    "\n",
    "        BIND (STRAFTER(STR(?uri), \"address/\") AS ?id)\n",
    "        BIND (STRAFTER(STR(?coords_dirty), \"4283> \") AS ?coords)\n",
    "    }\n",
    "    ORDER BY ?id\n",
    "    \"\"\"\n",
    "for r in g.query(q):\n",
    "    match = re.search(\"POINT\\((\\d+\\.\\d+)\\s(\\-\\d+\\.\\d+)\\)\", r[\"coords\"])\n",
    "    long = float(match.group(1))\n",
    "    lat = float(match.group(2))\n",
    "    addresses_csv += f'\\\"{r[\"addr\"]}\\\",{long},{lat}\\n'\n",
    "\n",
    "print(addresses_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the CSV into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "addresses_df = pd.read_csv(StringIO(addresses_csv))\n",
    "\n",
    "print(addresses_df[\"Longitude\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the first 5 rows of the DataFrame directly using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "addresses_df[:5].plot(kind=\"scatter\", x=\"Longitude\", y=\"Latitude\", s=50, figsize=(10,10))\n",
    "\n",
    "for i, label in enumerate(addresses_df[:5]):\n",
    "    plt.annotate(addresses_df[\"Address\"][i], (addresses_df[\"Longitude\"][i], addresses_df[\"Latitude\"][i]))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 5.2 Convert to common format - GeoJSON\n",
    "\n",
    "Import Python conversion tools (shapely)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import shapely.wkt\n",
    "from shapely.geometry import MultiPoint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through the graph using ordinary Python loops, not a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "points_list = []\n",
    "\n",
    "for s, p, o in g.triples((None, RDF.type, GNAF.Address)):\n",
    "    for s2, p2, o2 in g.triples((s, GEO.hasGeometry, None)):\n",
    "        for s3, p3, o3 in g.triples((o2, GEO.asWKT, None)):\n",
    "            points_list.append(\n",
    "                shapely.wkt.loads(str(o3).replace(\"<http://www.opengis.net/def/crs/EPSG/0/4283> \", \"\"))\n",
    "            )\n",
    "\n",
    "mp = MultiPoint(points=points_list)\n",
    "\n",
    "geojson = shapely.geometry.mapping(mp)\n",
    "print(json.dumps(geojson, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another, better, GeoJSON export - including Feature information.\n",
    "\n",
    "First, build a Python dictionary matching the GeoJSON specification, then export it to JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "geo_json_features = []\n",
    "\n",
    "# same query as above\n",
    "for r in g.query(q):\n",
    "    match = re.search(\"POINT\\((\\d+\\.\\d+)\\s(\\-\\d+\\.\\d+)\\)\", r[\"coords\"])\n",
    "    long = float(match.group(1))\n",
    "    lat = float(match.group(2))\n",
    "    geo_json_features.append({\n",
    "        \"type\": \"Feature\", \n",
    "        \"properties\": { \"name\": r[\"addr\"] },\n",
    "        \"geometry\": { \n",
    "            \"type\": \"Point\", \n",
    "            \"coordinates\": [ long, lat ] \n",
    "        } \n",
    "    })\n",
    "    \n",
    "geo_json_data = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"name\": \"test-points-short-named\",\n",
    "    \"crs\": { \"type\": \"name\", \"properties\": { \"name\": \"urn:ogc:def:crs:OGC:1.3:CRS84\" } },\n",
    "    \"features\": geo_json_features\n",
    "}\n",
    "\n",
    "import json\n",
    "geo_json = json.dumps(geo_json_data, indent=4)\n",
    "print(geo_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Export the data and view it in a GeoJSON map viewer, such as http://geojsonviewer.nsspot.net/ or QGIS (desktop_.\n",
    "\n",
    "## Concluding remarks\n",
    "\n",
    "* Semantic Web, realised through Linked Data, builds a global machine-readable data system\n",
    "* the RDF data structure is used\n",
    "    * to link things\n",
    "    * to define things, and the links\n",
    "* specialised parts of the Sem Web can represent a/any domain\n",
    "    * e.g. spatial\n",
    "    * e.g. Addresses\n",
    "* powerful graph pattern matching queries, SPARQL, can be used to subset (federated) Sem Web data\n",
    "* RDF manipulation libraries exist\n",
    "    * can convert to other, common forms, e.g. CSV GeoJSON\n",
    "* _do as much data science work as you can with well-defined models!_\n",
    "\n",
    "## License\n",
    "All the content in this repository is licensed under the [CC BY 4.0 license](https://creativecommons.org/licenses/by/4.0/). Basically, you can:\n",
    "\n",
    "* copy and redistribute the material in any medium or format\n",
    "* remix, transform, and build upon the material for any purpose, even commercially\n",
    "\n",
    "You just need to:\n",
    "\n",
    "* give appropriate credit, provide a link to the license, and indicate if changes were made\n",
    "* not apply legal terms or technological measures that legally restrict others from doing anything the license permits\n",
    "\n",
    "## Contact Information\n",
    "**Dr Nicholas J. Car**<br />\n",
    "*Data Systems Architect*<br />\n",
    "[SURROUND Australia Pty Ltd](https://surroundaustralia.com)<br />\n",
    "<nicholas.car@surroundaustralia.com><br />\n",
    "GitHub: [nicholascar](https://github.com/nicholascar)<br />\n",
    "ORCID: <https://orcid.org/0000-0002-8742-7730><br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}